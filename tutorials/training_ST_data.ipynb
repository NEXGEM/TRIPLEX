{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.path.basename(os.getcwd()) == 'tutorials':\n",
    "    # Change to parent directory\n",
    "    os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocess.pipeline import TriplexPipeline, get_config                        \n",
    "from src.preprocess.pipeline.utils import get_available_gpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing for TRIPLEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=\"YOUR HUGGING FACE TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hest_config = {\n",
    "    # Basic configuration\n",
    "    'input_dir': './input/ST/andersson',  \n",
    "    'output_dir': './input/ST/andersson', \n",
    "    'mode': 'hest',\n",
    "    \n",
    "    # Preprocessing parameters\n",
    "    'slide_ext': '.tif',\n",
    "    'save_neighbors': True,\n",
    "    'n_splits': 8,\n",
    "    'n_top_hvg': 50,\n",
    "    'n_top_heg': 1000,\n",
    "    \n",
    "    # Feature extraction parameters\n",
    "    'model_name': 'uni_v1', # or cigar\n",
    "    'batch_size': 1024,\n",
    "    'num_workers': 4,\n",
    "    'feature_type': 'both',\n",
    "    'gpus': [0]\n",
    "}\n",
    "\n",
    "pipeline = TriplexPipeline(hest_config)\n",
    "pipeline.run_pipeline()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hest_config = {\n",
    "    # Basic configuration\n",
    "    'input_dir': './input/ST/andrew',  \n",
    "    'output_dir': './input/ST/andrew', \n",
    "    'mode': 'hest',\n",
    "    \n",
    "    # Preprocessing parameters\n",
    "    'slide_ext': '.tif',\n",
    "    'save_neighbors': True,\n",
    "    'n_splits': 4,\n",
    "    'n_top_hvg': 50,\n",
    "    'n_top_heg': 1000,\n",
    "    \n",
    "    # Feature extraction parameters\n",
    "    'model_name': 'uni_v1', # or cigar\n",
    "    'batch_size': 1024,\n",
    "    'num_workers': 4,\n",
    "    'feature_type': 'both',\n",
    "    'gpus': [0]\n",
    "}\n",
    "\n",
    "pipeline = TriplexPipeline(hest_config)\n",
    "pipeline.run_pipeline()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hest_config = {\n",
    "    # Basic configuration\n",
    "    'input_dir': './input/ST/bryan',  \n",
    "    'output_dir': './input/ST/bryan', \n",
    "    'mode': 'hest',\n",
    "    \n",
    "    # Preprocessing parameters\n",
    "    'slide_ext': '.tif',\n",
    "    'save_neighbors': True,\n",
    "    'n_splits': 8,\n",
    "    'n_top_hvg': 50,\n",
    "    'n_top_heg': 1000,\n",
    "    \n",
    "    # Feature extraction parameters\n",
    "    'model_name': 'uni_v1', # or cigar\n",
    "    'batch_size': 1024,\n",
    "    'num_workers': 4,\n",
    "    'feature_type': 'both',\n",
    "    'gpus': [0]\n",
    "}\n",
    "\n",
    "pipeline = TriplexPipeline(hest_config)\n",
    "pipeline.run_pipeline()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic pre-procssing (ST-Net, HisToGene, Hist2ST, BLEEP)\n",
    "\n",
    "- You can skip this if you've already done the pre-processing for TRIPLEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hest_config = {\n",
    "    # Basic configuration\n",
    "    'input_dir': './input/ST/andersson',  \n",
    "    'output_dir': './input/ST/andersson', \n",
    "    'mode': 'hest',\n",
    "    \n",
    "    # Preprocessing parameters\n",
    "    'slide_ext': '.tif',\n",
    "    'save_neighbors': False,\n",
    "    'n_splits': 8,\n",
    "    'n_top_hvg': 50,\n",
    "    'n_top_heg': 1000,\n",
    "}\n",
    "\n",
    "pipeline = TriplexPipeline(hest_config)\n",
    "pipeline.preprocess()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hest_config = {\n",
    "    # Basic configuration\n",
    "    'input_dir': './input/ST/andrew',  \n",
    "    'output_dir': './input/ST/andrew', \n",
    "    'mode': 'hest',\n",
    "    \n",
    "    # Preprocessing parameters\n",
    "    'slide_ext': '.tif',\n",
    "    'save_neighbors': False,\n",
    "    'n_splits': 4,\n",
    "    'n_top_hvg': 50,\n",
    "    'n_top_heg': 1000,\n",
    "}\n",
    "\n",
    "pipeline = TriplexPipeline(hest_config)\n",
    "pipeline.preprocess()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hest_config = {\n",
    "    # Basic configuration\n",
    "    'input_dir': './input/ST/bryan',  \n",
    "    'output_dir': './input/ST/bryan', \n",
    "    'mode': 'hest',\n",
    "    \n",
    "    # Preprocessing parameters\n",
    "    'slide_ext': '.tif',\n",
    "    'save_neighbors': False,\n",
    "    'n_splits': 8,\n",
    "    'n_top_hvg': 50,\n",
    "    'n_top_heg': 1000,\n",
    "}\n",
    "\n",
    "pipeline = TriplexPipeline(hest_config)\n",
    "pipeline.preprocess()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing for EGN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can skip this if you've already done the pre-processing for TRIPLEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hest_config = {\n",
    "    # Basic configuration\n",
    "    'input_dir': './input/ST/andersson',  \n",
    "    'output_dir': './input/ST/andersson', \n",
    "    'mode': 'hest',\n",
    "    \n",
    "    # Preprocessing parameters\n",
    "    'slide_ext': '.tif',\n",
    "    'save_neighbors': False,\n",
    "    'n_splits': 8,\n",
    "    'n_top_hvg': 50,\n",
    "    'n_top_heg': 1000,\n",
    "    \n",
    "    # Feature extraction parameters\n",
    "    'model_name': 'uni_v1', # or cigar\n",
    "    'batch_size': 1024,\n",
    "    'num_workers': 4,\n",
    "    'feature_type': 'global',\n",
    "    'gpus': [0]\n",
    "}\n",
    "\n",
    "pipeline = TriplexPipeline(hest_config)\n",
    "pipeline.run_pipeline()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hest_config = {\n",
    "    # Basic configuration\n",
    "    'input_dir': './input/ST/andrew',  \n",
    "    'output_dir': './input/ST/andrew', \n",
    "    'mode': 'hest',\n",
    "    \n",
    "    # Preprocessing parameters\n",
    "    'slide_ext': '.tif',\n",
    "    'save_neighbors': False,\n",
    "    'n_splits': 4,\n",
    "    'n_top_hvg': 50,\n",
    "    'n_top_heg': 1000,\n",
    "    \n",
    "    # Feature extraction parameters\n",
    "    'model_name': 'uni_v1', # or cigar\n",
    "    'batch_size': 1024,\n",
    "    'num_workers': 4,\n",
    "    'feature_type': 'global',\n",
    "    'gpus': [0]\n",
    "}\n",
    "\n",
    "pipeline = TriplexPipeline(hest_config)\n",
    "pipeline.run_pipeline()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hest_config = {\n",
    "    # Basic configuration\n",
    "    'input_dir': './input/ST/bryan',  \n",
    "    'output_dir': './input/ST/bryan', \n",
    "    'mode': 'hest',\n",
    "    \n",
    "    # Preprocessing parameters\n",
    "    'slide_ext': '.tif',\n",
    "    'save_neighbors': False,\n",
    "    'n_splits': 8,\n",
    "    'n_top_hvg': 50,\n",
    "    'n_top_heg': 1000,\n",
    "    \n",
    "    # Feature extraction parameters\n",
    "    'model_name': 'uni_v1', # or cigar\n",
    "    'batch_size': 1024,\n",
    "    'num_workers': 4,\n",
    "    'feature_type': 'global',\n",
    "    'gpus': [0]\n",
    "}\n",
    "\n",
    "pipeline = TriplexPipeline(hest_config)\n",
    "pipeline.run_pipeline()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Additional pre-processing for EGN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```bash\n",
    "python src/model/EGN/build_exemplar.py --data_dir input/ST/andersson\n",
    "python src/model/EGN/build_exemplar.py --data_dir input/ST/andrew\n",
    "python src/model/EGN/build_exemplar.py --data_dir input/ST/bryan\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a dataset to be used for training\n",
    "```bash\n",
    "DATASET=\"ST/andersson\"\n",
    "```\n",
    "\n",
    "Run the following script to train multiple models using cross-validation:\n",
    "\n",
    "```bash\n",
    "NUM_GPU=2\n",
    "MODE=cv\n",
    "\n",
    "# Define models to train\n",
    "MODELS=(\"TRIPLEX\" \"StNet\" \"EGN\" \"BLEEP\")\n",
    "\n",
    "# Submit jobs for each model\n",
    "for MODEL in \"${MODELS[@]}\"; do\n",
    "     python src/main.py --config_name $DATASET/$MODEL --gpu $NUM_GPU --mode $MODE\n",
    "done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training, evaluate each model with the following script:\n",
    "\n",
    "```bash\n",
    "declare -A MODELS=(\n",
    "     [\"TRIPLEX\"]=\"Log name for TRIPLEX\"\n",
    "     [\"StNet\"]=\"Log name for StNet\"\n",
    "     [\"EGN\"]=\"Log name for EGN\"\n",
    "     [\"BLEEP\"]=\"Log name for BLEEP\"\n",
    ")\n",
    "\n",
    "# Loop through each model\n",
    "for MODEL in \"${!MODELS[@]}\"; do\n",
    "     TIMESTAMP=${MODELS[$MODEL]}\n",
    "     python src/main.py --config_name $DATASET/$MODEL --gpu 1 --mode eval --timestamp $TIMESTAMP\n",
    "     python src/experiment/agg_results.py --dataset $DATASET --model $MODEL --timestamp $TIMESTAMP\n",
    "done\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
