{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRIPLEX Data Processing Tutorial\n",
    "\n",
    "This tutorial provides a comprehensive guide to using the TRIPLEX pipeline for processing spatial transcriptomics (ST) data integrated with whole slide images (WSI). The pipeline supports various tasks including data preprocessing, feature extraction, and data preparation for both training and inference.\n",
    "\n",
    "## Overview of the Pipeline\n",
    "\n",
    "The TRIPLEX pipeline integrates several key components:\n",
    "\n",
    "1. **Data Preprocessing**: Preparing spatial transcriptomics data and whole slide images\n",
    "2. **Feature Extraction**: Extracting features from WSI patches using deep learning models\n",
    "3. **Dataset Preparation**: Creating datasets suitable for training and inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.path.basename(os.getcwd()) == 'tutorials':\n",
    "    # Change to parent directory\n",
    "    os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocess.pipeline import TriplexPipeline, get_config                        \n",
    "from src.preprocess.pipeline.utils import get_available_gpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Check GPU Availability\n",
    "\n",
    "The pipeline can leverage GPU acceleration for feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check available GPUs\n",
    "available_gpus = get_available_gpus()\n",
    "print(f\"Available GPUs: {len(available_gpus)}\")\n",
    "\n",
    "# If running on GPU, show CUDA information\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"Detected GPUs: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration System\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = os.path.abspath('./src/preprocess')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the default configuration\n",
    "try:\n",
    "    default_config = get_config(f\"{working_dir}\", 'default')\n",
    "    print(\"Default configuration parameters:\")\n",
    "    for key, value in sorted(default_config.items()):\n",
    "        print(f\"  {key}: {value}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Default configuration file not found. Make sure to create it first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Creating a Custom Configuration\n",
    "\n",
    "You can create a custom configuration by merging dictionaries or loading from a YAML file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom configuration by overriding default values\n",
    "custom_config = {\n",
    "    'mode': 'train',\n",
    "    'platform': 'visium',\n",
    "    'input_dir': '/path/to/input/data',\n",
    "    'output_dir': '/path/to/output/data',\n",
    "    'slide_ext': '.svs',\n",
    "    'patch_size': 224,\n",
    "    'slide_level': 0,\n",
    "    'save_neighbors': True,\n",
    "    'total_gpus': min(2, len(available_gpus))  # Use at most 2 GPUs\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Basic Configuration**\n",
    "- **input_dir**: Directory containing input data (ST data and/or WSI images)\n",
    "- **output_dir**: Directory where all processed data and results will be saved\n",
    "- **mode**: Pipeline operation mode (train, inference, or hest) \\\n",
    "    - train: For training new models\n",
    "    - inference: For running predictions with existing models\n",
    "    - hest: For data from Hest-1K\n",
    "- **platform**: Spatial transcriptomics platform type (visium, xenium, ST)\n",
    "\n",
    "#### **Preprocessing Parameters**\n",
    "- **slide_ext**: File extension for whole slide images (default: .svs)\n",
    "- **patch_size**: Size in pixels of extracted image patches (default: 224)\n",
    "- **slide_level**: Pyramid level of the slide to use (0 is highest resolution, default: 0)\n",
    "- **step_size**: Distance between extracted patches in pixels (default: 160)\n",
    "- **save_neighbors**: Whether to save neighboring patches for contextual analysis (default: False)\n",
    "\n",
    "#### **Feature Extraction Parameters**\n",
    "- **model_name**: Deep learning model to use for feature extraction (default: uni_v1)\n",
    "- **num_n**: Number of neighbors to consider for feature extraction (default: 5)\n",
    "- **batch_size**: Batch size for feature extraction (default: 1024)\n",
    "- **num_workers**: Number of worker processes for data loading (default: 4)\n",
    "- **feature_type**: Type of features to extract (global, neighbor, or both)\n",
    "\n",
    "#### **Additional Parameters**\n",
    "- **n_splits**: Number of data splits for cross-validation (default: 4)\n",
    "- **n_top_hvg**: Number of top highly variable genes to select (default: 50)\n",
    "- **n_top_heg**: Number of top highly expressed genes to select (default: 1000)\n",
    "- **total_gpus**: Total number of GPUs to utilize (default: automatically detected)\n",
    "- **overwrite**: Whether to overwrite existing results (default: False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The Data Processing Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Complete Pipeline Execution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Processing HEST data (Andersson; BC1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you've already downloaded the HEST data, enter the path to the hest_dir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of processing HEST data\n",
    "hest_config = {\n",
    "    # Basic configuration\n",
    "    'input_dir': './input/ST/andersson',  \n",
    "    'output_dir': './input/ST/andersson', \n",
    "    'mode': 'hest',\n",
    "    \n",
    "    # Preprocessing parameters\n",
    "    'hest_dir': '/data-hdd/home/shared/spRNAseq/public/hest_data',\n",
    "    'slide_ext': '.tif',\n",
    "    'save_neighbors': True,\n",
    "    \n",
    "    # Feature extraction parameters\n",
    "    'model_name': 'uni_v1',\n",
    "    'batch_size': 1024,\n",
    "    'num_workers': 4,\n",
    "    'feature_type': 'both',\n",
    "    'gpus': [0]\n",
    "}\n",
    "\n",
    "pipeline = TriplexPipeline(hest_config)\n",
    "pipeline.run_pipeline()  # This will run preprocessing and feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you haven't downloaded the HEST data, login to HF with your token and run the pipeline. \\\n",
    "The HEST data will automatically be downloaded into the input_dir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=\"YOUR HUGGING FACE TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of processing HEST data\n",
    "hest_config = {\n",
    "    # Basic configuration\n",
    "    'input_dir': './input/ST/andersson',  \n",
    "    'output_dir': './input/ST/andersson', \n",
    "    'mode': 'hest',\n",
    "    \n",
    "    # Preprocessing parameters\n",
    "    'slide_ext': '.tif',\n",
    "    'save_neighbors': True,\n",
    "    \n",
    "    # Feature extraction parameters\n",
    "    'model_name': 'uni_v1',\n",
    "    'batch_size': 1024,\n",
    "    'num_workers': 4,\n",
    "    'feature_type': 'both',\n",
    "    'gpus': [0]\n",
    "}\n",
    "\n",
    "pipeline = TriplexPipeline(hest_config)\n",
    "pipeline.run_pipeline()  # This will run preprocessing and feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Processing Visium data (GSE240429)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of processing Visium data for training\n",
    "# Example of processing HEST data\n",
    "visium_config = {\n",
    "    # Basic configuration\n",
    "    'input_dir': './GSE240429',  # Replace with actual path\n",
    "    'output_dir': 'input/GSE240429',\n",
    "    'mode': 'train',\n",
    "    \n",
    "    # Preprocessing parameters\n",
    "    'slide_ext': '.tif',\n",
    "    'save_neighbors': True,\n",
    "    \n",
    "    # Feature extraction parameters\n",
    "    'model_name': 'uni_v1',\n",
    "    'batch_size': 1024,\n",
    "    'num_workers': 4,\n",
    "    'feature_type': 'both',\n",
    "    'gpus': [0]\n",
    "}\n",
    "\n",
    "pipeline = TriplexPipeline(visium_config)\n",
    "pipeline.run_pipeline() # This will run preprocessing and feature extraction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: Inference on WSI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of inference on WSI data\n",
    "# Example of processing Visium data for training\n",
    "# Example of processing HEST data\n",
    "inference_config = {\n",
    "    # Basic configuration\n",
    "    'input_dir': '/path/to/wsi/data',  # Replace with actual path\n",
    "    'output_dir': '/input/data/path',  # Replace with actual path\n",
    "    'mode': 'inference',\n",
    "    \n",
    "    # Preprocessing parameters\n",
    "    'slide_ext': '.mrxs',\n",
    "    'save_neighbors': True,\n",
    "    'slide_level': 1,  # Use level 1 for faster processing\n",
    "    \n",
    "    # Feature extraction parameters\n",
    "    'model_name': 'uni_v1',\n",
    "    'batch_size': 1024,\n",
    "    'num_workers': 4,\n",
    "    'feature_type': 'both',\n",
    "    'gpus': [0,1,2,3]\n",
    "}\n",
    "\n",
    "\n",
    "pipeline = TriplexPipeline(inference_config)\n",
    "pipeline.run_pipeline() # This will run preprocessing and feature extraction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Step by step processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Processing HEST data (Andersson; BC1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Data Preprocessing\n",
    "\n",
    "The first step is preprocessing the data. This includes:\n",
    "- Loading and processing spatial transcriptomics data\n",
    "- Extracting patches from whole slide images\n",
    "- Preparing gene sets for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Understanding Preprocessing Modes***\n",
    "\n",
    "TRIPLEX supports three main preprocessing modes:\n",
    "\n",
    "1. **train mode**: Used to prepare data for model training\n",
    "   - Processes both spatial transcriptomics data and WSIs\n",
    "   - Creates patch datasets from WSIs\n",
    "   - Extracts gene sets (highly variable genes and highly expressed genes)\n",
    "   - Splits data for cross-validation\n",
    "\n",
    "2. **hest mode**: Used for HEST (Histology-Enhanced Spatial Transcriptomics) data\n",
    "   - Loads pre-processed HEST data\n",
    "   - Extracts patches and neighbor information\n",
    "   - Prepares gene sets for training\n",
    "\n",
    "3. **inference mode**: Used to prepare data for inference\n",
    "   - Processes WSIs only (no spatial transcriptomics data required)\n",
    "   - Extracts patches and coordinates for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of processing HEST data\n",
    "hest_config = {\n",
    "    # Basic configuration\n",
    "    'input_dir': './input/ST/andersson',  \n",
    "    'output_dir': './input/ST/andersson', \n",
    "    'mode': 'hest',\n",
    "    \n",
    "    # Preprocessing parameters\n",
    "    'hest_dir': '/data-hdd/home/shared/spRNAseq/public/hest_data',\n",
    "    'slide_ext': '.tif',\n",
    "    'save_neighbors': True,\n",
    "    \n",
    "    # Feature extraction parameters\n",
    "    'model_name': 'uni_v1',\n",
    "    'batch_size': 1024,\n",
    "    'num_workers': 4,\n",
    "    'feature_type': 'both',\n",
    "    'gpus': [0]\n",
    "}\n",
    "\n",
    "pipeline = TriplexPipeline(hest_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Feature Extraction\n",
    "\n",
    "After preprocessing, the next step is to extract features from the WSI patches. TRIPLEX extracts two types of features:\n",
    "\n",
    "1. **Global features**: Features extracted from individual patches\n",
    "2. **Neighbor features**: Features that incorporate neighborhood context\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Feature Extraction Models***\n",
    "\n",
    "TRIPLEX supports several feature extraction models:\n",
    "\n",
    "- **cigar**: A self-supervised model trained on histopathology images\n",
    "- Other models from the HEST model zoo can also be used\n",
    "\n",
    "The default is `cigar`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2-1) Sequential Feature Extraction**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.run_extraction()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2-2) Parallel Feature Extraction**\n",
    "\n",
    "For large datasets, TRIPLEX can perform feature extraction in parallel across multiple GPUs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of processing HEST data\n",
    "parallel_config = {\n",
    "    # Basic configuration\n",
    "    'input_dir': './input/ST/andersson',  \n",
    "    'output_dir': './input/ST/andersson', \n",
    "    'mode': 'hest',\n",
    "    \n",
    "    # Preprocessing parameters\n",
    "    'hest_dir': '/data-hdd/home/shared/spRNAseq/public/hest_data',\n",
    "    'slide_ext': '.tif',\n",
    "    'save_neighbors': True,\n",
    "    \n",
    "    # Feature extraction parameters\n",
    "    'model_name': 'uni_v1',\n",
    "    'batch_size': 1024,\n",
    "    'num_workers': 4,\n",
    "    'feature_type': 'both',\n",
    "    'gpus': [0, 1, 2, 3]\n",
    "}\n",
    "\n",
    "print(f\"Parallel extraction would use {len(available_gpus)} GPUs\")\n",
    "pipeline = TriplexPipeline(parallel_config)\n",
    "pipeline.run_parallel_extraction()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Understanding the Output Structure\n",
    "\n",
    "The TRIPLEX pipeline generates several output directories and files. Here's a guide to the output structure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "output_dir/\n",
    "├── patches/           # Extracted patches from WSIs\n",
    "│   └── neighbor/      # Neighbor patches (if save_neighbors is True)\n",
    "├── adata/             # Processed gene expression data\n",
    "│   └── *.h5ad         # AnnData files with gene expression\n",
    "├── emb/               # Extracted features\n",
    "│   ├── global/        # Global features\n",
    "│   │   └── cigar/     # Features from the cigar model\n",
    "│   └── neighbor/      # Neighbor features\n",
    "│       └── cigar/     # Features from the cigar model\n",
    "├── pos/               # Patch positions for inference\n",
    "├── var_50genes.json   # Highly variable genes\n",
    "└── mean_1000genes.json # Highly expressed genes\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Best Practices and Tips\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Memory Management\n",
    "\n",
    "- Adjust `batch_size` based on your GPU memory\n",
    "- Use `num_workers` based on your CPU cores (typically 4-8 is sufficient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Performance Optimization\n",
    "\n",
    "- Use multiple GPUs for feature extraction on large datasets\n",
    "- For very large datasets, process files in batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Quality Control\n",
    "\n",
    "- Check intermediate outputs (patches, gene sets) to ensure quality\n",
    "- If feature extraction fails, try reducing batch size\n",
    "- Verify that gene expression data properly aligns with WSI patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Troubleshooting Common Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Memory Errors\n",
    "\n",
    "If you encounter CUDA out of memory errors:\n",
    "- Reduce batch size\n",
    "- Process fewer files simultaneously"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 File Format Issues\n",
    "\n",
    "If you have issues with file formats:\n",
    "- Ensure your slide extension matches the actual files\n",
    "- For Aperio SVS files, use '.svs'\n",
    "- For MRXS files, use '.mrxs'\n",
    "- For TIFF files, use '.tif' or '.tiff'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Platform-Specific Issues\n",
    "\n",
    "For platform-specific preprocessing:\n",
    "- Visium data should have the standard 10X Visium folder structure\n",
    "- For HEST data, ensure the data is formatted according to HEST specifications\n",
    "- For custom platforms, you may need to modify the data loading functions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TRIPLEX",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
